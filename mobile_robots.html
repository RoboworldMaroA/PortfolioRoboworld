<!doctype html>
<html lang="en">

<head>

  <title>Mobile Robots - Robo-world</title>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />

  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"
    integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

  <link href="CSS_Portfolio/portfolioMobileRobots.css?v=1.3" rel="stylesheet" type="text/css" />
  <link href='https://fonts.googleapis.com/css?family=Rajdhani' rel='stylesheet'>

</head>

<body>
  <header>
    <section class="row justify-content-md-center" id="navbarIndex">
      <div class="col-sm-12 col-md-10 col-lg-10 ">

        <nav class="navbar navbar-expand-lg navbar-custom">
          <a class="navbar-brand" href="index.html"><b>ROBO-WORLD</b></a>
          <button class="navbar-toggler custom-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false"
            aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
          </button>

          <div class="collapse navbar-collapse" id="navbarSupportedContent">
            <ul class="navbar-nav mr-auto">
              <li class="nav-item active">
                <a class="nav-link" href="index.html">Home <span class="sr-only">(current)</span></a>
              </li>

              <li class="nav-item dropdown">
                <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown"
                  aria-haspopup="true" aria-expanded="false">
                  Projects
                </a>
                <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                  <a class="dropdown-item" href="automations.html">Automations</a>
                  <a class="dropdown-item" href="mobile_robots.html">Mobile Robots</a>
                  <a class="dropdown-item" href="https://smartluggage2023.ew.r.appspot.com/">Smart Luggage</a>
                  <a class="dropdown-item" href="softwareDevelopmentV2.html">Software Development</a>
                  <a class="dropdown-item"
                    href="https://manage-customers-4x6n9.ondigitalocean.app/objectDetection.html">
                    Computer Vision</a>
                </div>
              </li>

              <li class="nav-item">
                <a class="nav-link" href="about_me.html">About me</a>
              </li>


              <!-- <li class="nav-item dropdown">
                <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown"
                  aria-haspopup="true" aria-expanded="false">
                  Language
                </a>
                <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                  <a class="dropdown-item" href="index.html">EN</a>

                </div>
              </li> -->

            </ul>
            <!-- <form class="form-inline my-2 my-lg-0">
          <input class="form-control mr-sm-2" type="search" placeholder="Search" aria-label="Search">
          <button class="btn btn-outline-light my-2 my-sm-0" type="submit">Search</button>
        </form> -->
          </div>
        </nav>
      </div>
    </section>
  </header>



  <!-- INTRODUCING MOBILE ROBOTS -->

  <!--Main Contetnt-->
  <main role="main" class="container-fluid">
    <section class="row justify-content-md-center" id="textInMobileRobotsIntroduction">
      <div class="col-sm-10 col-md-10 col-lg-10">
        <!-- <h1> Mobile robots</h1> -->
        <h1 id="typewriter"></h1>
        <br>
        <p>I chose mobile robots because they have many applications and programming them is a difficult task,
          especially when it comes to detecting objects using cameras and mapping.
          The robot has many peripheral devices, such as motors and sensors, and can be expanded with an additional arm
          for lifting objects. </p>
        <p>Additionally, this is the first step if you want to design your own ADAS, such as those used in modern cars.
        </p>

      </div>

    </section>
  </main>


  <div class="container-fluid">
    <section class="row justify-content-md-center" id="textInTrainModelStartStop">
      <div class="col-sm-10 col-md-10 col-lg-10">

        <p>
          In my latest project, I successfully built a mobile robot integrated with a camera and powered by a Raspberry
          Pi 4. Utilizing the MobileNetV2 model, I retrained the final layers to recognize specific command signs: "GO,"
          "Turn Right," and "STOP."

          Leveraging my knowledge of Deep Learning and Transfer Learning, I effectively programmed the robot using
          Python to interpret these signs and respond accordingly. The robot initiates movement upon seeing the "GO"
          sign, navigates a right turn when it detects the "Turn Right" sign, and comes to a halt when presented with
          the "STOP" sign.

          This demonstration underscores the potential of combining advanced machine learning techniques with practical
          robotics to create responsive and intelligent systems. Check out the video to see the robot in action!

        </p>
        <p>
          <!-- I used program on<a
            href="https://colab.research.google.com/drive/1hf11j_eM67ogYupwv1YG7da321A2KVGg?usp=sharing"> <span
              style="color: rgb(168, 101, 14);">Google Colab
              Notebook </span></a> to train a model.

          This code allows my robot to "make a decision" based on what it sees. -->
          <!-- To do that I used Deep Learning. I retrained few last layers pertained Mobile Net v2 model. It is called
        Transfer Learning. -->
        </p>

        <p>
          <!-- Using the Raspberry Pi alone, I can only get 2 FPS, but the Coral accelerator allows me to increase that speed
        to
        9 FPS. As you can see, the Raspberry Pi allows me to create an autonomous robot with near real-time object
        detection -->
          <!-- but when the robot is driving and using other sensors, the frame rate drops dramatically.  -->
          <!-- In my
        opinion, the
        Raspberry Pi is a very good tool for basic task, but for a more complex task like ROS, it's probably not good
        enough. I think that something from the Jetson range would
        be a better option because has better GPU. -->
        </p>

      </div>
    </section>
  </div>

  <div class="wave"></div>
  <!-- Videos Tensorflow Raspberry Pi 4 , Google Coral -->
  <section id="videosUnderDescriptionTensorflow">
    <div class="container">
      <div class="col-lg-12">
        <div class="row">
          <article class="col-sm-offset-0 col-sm-6  col-lg-6 col-md-6">
            <div class="embed-responsive embed-responsive-4by3" id="videoControlerMobileRobot">
              <iframe width="364" height="647"
                src="projects/mobile_robots/fourWheelsRaspberryPi/robot_recognize_go_turn_right_and_stop2.mp4"
                title="TensorflowObjectRecognitionStartStop"
                allow="accelerometer; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                allowfullscreen></iframe>
            </div>
            <p class="description-under-the-photo"><a href="https://github.com/RoboworldMaroA/Roboworld">GO,
                Turn Right and Stop
              </a></p>
            <p>&nbsp;</p>
          </article>

          <article class=" col-sm-6 col-lg-6 col-md-6">
            <div class="embed-responsive embed-responsive-4by3" id="videoControlerMobileRobot3">
              <iframe width="364" height="647"
                src="projects/mobile_robots/fourWheelsRaspberryPi/robot_recognize_go_turn_right_and_stop_raspberry_view2_short.mp4"
                title="Tensorflow Driving Car"
                allow="accelerometer; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                allowfullscreen></iframe>
            </div>
            <p class="description-under-the-photo"><a href="https://github.com/RoboworldMaroA/Roboworld">Object
                Recognition with Google Coral</a></p>
          </article>
        </div>
      </div>
    </div>
  </section>







  <!--History-->
  <div id="history" class="container-fluid">
    <section class="row justify-content-md-center" id="textInMobileRobotsIntroduction">
      <div class="col-sm-10 col-md-10 col-lg-10">
        <h1> Previous projects</h1>


        <p> I became interested in building robots in 2008.
          These were completely different times, almost no one had heard of Arduino, and Raspberry Pi had not yet been
          born. Building a mobile robot required more work than today.
          For the first project, I decided to buy a development board with an Atmel chip. I had got online a books for
          programming microcontrollers in BASCOM.
          After a few weeks, I built a six-wheeled vehicle. It had two DC motors and four servos to turn the wheels.
          There is a proximity sensor installed at the front of the vehicle, which I built from scratch.
        </p>
      </div>

    </section>
  </div>


  <div class="wave"></div>
  <!-- Photos SIX WHEELS VEHICLE -->
  <section id="photosUnderDescriptionSixWheelVehicles">
    <div class="container">
      <div class="col-lg-12">
        <div class="row">
          <article class="col-sm-offset-0 col-sm-6  col-lg-6 col-md-6">
            <img src="indexPhotos/6_kolXS.jpg" alt="Six_weel_robot" class="img-fluid" />
            <p class="description-under-the-photo"><a href="https://github.com/RoboworldMaroA/Roboworld">6 wheel
                vehicle (BASCOM) </a></p>
          </article>
          <article class=" col-sm-6 col-lg-6 col-md-6"><img src="indexPhotos/six_wheel2.jpg" alt="design_robots"
              class="img-fluid" />
            <p class="description-under-the-photo"><a href="https://github.com/RoboworldMaroA/Roboworld">Design
                mobile robot </a></p>
          </article>
        </div>
      </div>
    </div>
  </section>

  <div class="wave2"></div>

  <!-- LINE FOLLOWER -->
  <div class="container-fluid">
    <section class="row justify-content-md-center" id="textInLineFollower">
      <div class="col-sm-10 col-md-10 col-lg-10">
        <p>
          In 2009 bought an Arduino Duemilanove which had an ATmega328p on board, a chip with more outputs and inputs
          than the ATmega8 that was used in six wheeled vehicle.
          Experimented a bit with diodes and buttons and started building a line follower.
          Decided that would postpone the six-wheeler project as it required more work and money(let's not forget the
          crisis).
          The driving direction is changed by adjusting the speed of the driven wheels.
          On the front is a sensor module for color recognition. On the back is an arduino and a motor controller
          built and a color sensor controller.
        </p>
      </div>
    </section>
  </div>
  <div class="wave"></div>

  <!-- Photos Line Follower -->
  <section id="videosUnderDescription">
    <div class="container">
      <div class="col-lg-12">
        <div class="row">
          <article class="col-sm-offset-0 col-sm-6  col-lg-6 col-md-6">
            <img src="projects/mobile_robots/line_follower_design.jpg" alt="line follower design" class="img-fluid" />
            <p class="description-under-the-photo"><a href="https://github.com/RoboworldMaroA/Roboworld">Design
                Line follower </a></p>
          </article>
          <article class=" col-sm-6 col-lg-6 col-md-6">

            <img tabindex="1" src="projects/mobile_robots/line_follower.jpg" alt="line_follower" class="img-fluid"
              title="Line_follower" />
            <p class="description-under-the-photo"><a href="https://github.com/RoboworldMaroA/Roboworld">Line
                follower (Arduino)</a></p>
            <p></p>
            <p>&nbsp;</p>
          </article>

          <article class="col-sm-6 col-lg-6 col-md-6">
            <div class="embed-responsive embed-responsive-4by3" id="videoControlerMobileRobot2">
              <iframe width="364" height="647" src="https://www.youtube.com/embed/ROTlCMCb9s8" title="line follower new"
                allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                allowfullscreen></iframe>
            </div>
            <p class="description-under-the-photo"><a href="https://github.com/RoboworldMaroA/Roboworld">Line
                Follower (Arduino)</a></p>
            <p></p>
          </article>
        </div>
      </div>
    </div>
  </section>

  <div class="wave2"></div>
  <!-- Four wheel Robots with Raspberry Pi -->
  <div class="container-fluid">
    <section class="row justify-content-md-center" id="textInFourWheelsRobot">
      <div class="col-sm-10 col-md-10 col-lg-10">

        <p>Until 2011, in my spare time, experimented with sonar and obstacle sensors and a sumo robot, but due to
          lack of time,
          stopped doing mobile robot and returned to the topic in 2020.
          Started building a mobile robot, this time 4 wheeled with Raspberry Pi.</p>
        <p>
          I realized very quickly that in order to continue this project, I had to learn Python.
          In two month did "Complete Python Developer: Zero to Mastery" and then
          "Master Computer Vision System and OpenCV3" on Udemy.
          These courses allowed me to start playing with Raspberry and building a robot that
          recognizes objects.
        </p>
      </div>
    </section>
  </div>
  <div class="wave"></div>

  <!-- Photos 4 Wheeels Wehicle -->
  <section id="photosFourWheelsRobot">
    <div class="container">
      <div class="col-lg-12">
        <div class="row">
          <article class="col-sm-5  col-lg-6 col-md-6">
            <img tabindex="1" src="projects/mobile_robots/fourWheelsRaspberryPi/4WheelsRaspberryPi3Front4samll.jpg "
              alt="4_wheels_vehicle" class="img-fluid " title="4 wheels with camera Tensorflow" />
            <p class="description-under-the-photo"><a href="https://github.com/RoboworldMaroA/Roboworld">4 wheels
                (Raspberry Pi, Google Coral)</a></p>
            <p>&nbsp;</p>
          </article>
          <article class=" col-sm-5 col-lg-6 col-md-6">
            <img src="projects/mobile_robots/fourWheelsRaspberryPi/4WheelsRaspberryPiInside5small.jpg"
              alt="4 wheels with camera" class="img-fluid " />
            <p class="description-under-the-photo"><a href="https://github.com/RoboworldMaroA/Roboworld">4 wheels
                with camera </a></p>
          </article>
        </div>
      </div>
    </div>
  </section>

  <div class="wave2"></div>
  <!-- Tensorflow  -->
  <div class="container-fluid">
    <section class="row justify-content-md-center" id="textInTensorflow">
      <div class="col-sm-10 col-md-10 col-lg-10">
        <p>
          As it turned out, the Raspberry Pi 3 has a weak processor and not enough RAM, which makes object
          recognition very slow.
          Started delving into the field of object recognition and found an interesting topic like Tensorflow.
          Decided to use Tensorflow Lite and the built-in model on a Raspberry Pi, but the image was still analyzed at
          2
          frames
          per second.
          That's why I bought a Google Coral accelerator which accelerated object recognition to 8 frames per second.
        </p>
      </div>
    </section>
  </div>

  <div class="wave"></div>
  <!-- Videos Tensorflow -->
  <section id="videosUnderDescriptionTensorflow">
    <div class="container">
      <div class="col-lg-12">
        <div class="row">
          <article class="col-sm-offset-0 col-sm-6  col-lg-6 col-md-6">
            <div class="embed-responsive embed-responsive-4by3" id="videoControlerMobileRobot">
              <iframe width="364" height="647"
                src="projects/mobile_robots/fourWheelsRaspberryPi/tensorflow_camera_on_table.mp4"
                title="TensorflowObjectRecognition"
                allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                allowfullscreen></iframe>
            </div>
            <p class="description-under-the-photo"><a href="https://github.com/RoboworldMaroA/Roboworld"
                role="definition">Tensorflow Object Recognition</a></p>
            <p>&nbsp;</p>
          </article>

          <article class=" col-sm-6 col-lg-6 col-md-6">
            <div class="embed-responsive embed-responsive-4by3" id="videoControlerMobileRobot3">
              <iframe width="364" height="647"
                src="projects/mobile_robots/fourWheelsRaspberryPi/tensorflow_object_recognition.mp4"
                title="Tensorflow Driving Car"
                allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                allowfullscreen></iframe>
            </div>
            <p class="description-under-the-photo"><a href="https://github.com/RoboworldMaroA/Roboworld"
                role="button">Tensorflow Driving Car</a></p>
          </article>
        </div>
      </div>
    </div>
  </section>

  <div class="wave2"></div>

  <div class="container-fluid">
    <section class="row justify-content-md-center" id="textInWebAppPythonAndFlask">
      <div class="col-sm-10 col-md-10 col-lg-10">
        <p>In 2020, I decided to take the Software Developer course, so I didn't have time to continue with the project
          until summer 2021.
        </p>

        <p>During the summer break, I used the new skills I acquired in the course and created a web application in
          Python and Flask
        </p>
        <p>This application allows me to remotely control the robot using a laptop or smartphone. </p>

      </div>
    </section>
  </div>

  <div class="wave"></div>
  <!-- Remote controller Python and FLASK-->
  <section class="videosUnderDescription">
    <div class="container">
      <div class="col-lg-12">
        <div class="row">

          <article class="col-sm-offset-0 col-sm-6  col-lg-6 col-md-6">
            <div class="embed-responsive embed-responsive-4by3">
              <iframe width="364" height="647" src="https://www.youtube.com/embed/r6CQq-H8rrE?si=Ru6zLO9dUyxqdZby"
                title="roboworld.MOV"
                allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                allowfullscreen></iframe>
            </div>
            <p class="description-under-the-photo"><a href="https://github.com/RoboworldMaroA/Roboworld">Web App
                (Python + Flask)</a></p>
            <p>&nbsp;</p>
          </article>

          <article class=" col-sm-6 col-lg-6 col-md-6">
            <div class="embed-responsive embed-responsive-4by3">
              <iframe width="364" height="647" src="https://www.youtube.com/embed/V-0G_KSmiI0"
                title="View Driving robot Auto drive"
                allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                allowfullscreen></iframe>
            </div>
            <p class="description-under-the-photo"><a href="https://github.com/RoboworldMaroA/Roboworld">Web App
                (Python + Flask)</a></p>
          </article>
        </div>
      </div>
    </div>
  </section>


  <div class="wave2"></div>
  <!-- Next stage of the project Tensorflow, Raspberry pi4 , Training Model-->
  <div class="container-fluid">
    <section class="row justify-content-md-center" id="textInTrainModel">
      <div class="col-sm-10 col-md-10 col-lg-10">

        <p>In 2022, during the Christmas break, I had some time to teach the Raspberry pi to recognize objects.</p>
        <p>I trained my system to recognize the remote control, cup, baubles and bin. To do this, I followed
          instructions from the official tensorflow manual.
          Prepared 300 photos of objects that I want to recognize. The problem is that for training purposes the size of
          the photos should be smaller than phone's camera.
          Photos should not be larger than 800x600 pixels, otherwise more computational time is needed for training.
          I used the Photoshop to do this, but unfortunately after some time realized it could take hours so had to find
          another way.
        </p>
        <p>
          Decided to make my own mini application that changes the resolution of photos.
          A program that allows me to change the resolution of photos in seconds is available on <a
            href="https://github.com/RoboworldMaroA/decreasePhotoSize/blob/main/README.md">GitHub</a>.
          Application allow to reduce size of the photos and videos.
          You can just download this app, no need to install and add the photos and videos that you want to convert to
          smaller size and run
          application.
        </p>
        <p>
          In the following videos is vision system with Raspberry pi4 (Tensorflow). Using the Coral accelerator allows
          increase to 14 frames per second.
        </p>

      </div>
    </section>
  </div>
  <div class="wave"></div>
  <!-- Videos Tensorflow Raspberry Pi 4 , Google Coral -->
  <section id="videosUnderDescriptionTensorflow">
    <div class="container">
      <div class="col-lg-12">
        <div class="row">
          <article class="col-sm-offset-0 col-sm-6  col-lg-6 col-md-6">
            <div class="embed-responsive embed-responsive-4by3" id="videoControlerMobileRobot">
              <iframe width="364" height="647"
                src="projects/mobile_robots/fourWheelsRaspberryPi/Trained_Moder_Remote_Cup_Tensorflow_Google_Colab.mp4"
                title="TensorflowObjectRecognition"
                allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                allowfullscreen></iframe>
            </div>
            <p class="description-under-the-photo"><a href="https://github.com/RoboworldMaroA/Roboworld">Tensorflow
                Object Recognition</a>
            </p>
            <p>&nbsp;</p>
          </article>

          <article class=" col-sm-6 col-lg-6 col-md-6">
            <div class="embed-responsive embed-responsive-4by3" id="videoControlerMobileRobot3">
              <iframe width="364" height="647" src="https://www.youtube.com/embed/I5tulnijCsI?si=brZrce72K6UpnytB"
                title="Tensorflow Driving Car"
                allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                allowfullscreen></iframe>
            </div>
            <p class="description-under-the-photo"><a href="https://github.com/RoboworldMaroA/Roboworld"
                role="definition">Object
                Recognition with Google Coral</a></p>
          </article>
        </div>
      </div>
    </div>
  </section>

  <!-- <div class="wave2"></div> -->
  <!-- 28 June 2023 Trained model to recognize Start, Stop, turn back, turn left and right-->
  <!-- <div class="container-fluid">
    <section class="row justify-content-md-center" id="textInTrainModelStartStop">
      <div class="col-sm-10 col-md-10 col-lg-10">

        <p>
          In my latest project, I successfully built a mobile robot integrated with a camera and powered by a Raspberry
          Pi 4. Utilizing the MobileNetV2 model, I retrained the final layers to recognize specific command signs: "GO,"
          "Turn Right," and "STOP."

          Leveraging my knowledge of Deep Learning and Transfer Learning, I effectively programmed the robot using
          Python to interpret these signs and respond accordingly. The robot initiates movement upon seeing the "GO"
          sign, navigates a right turn when it detects the "Turn Right" sign, and comes to a halt when presented with
          the "STOP" sign.

          This demonstration underscores the potential of combining advanced machine learning techniques with practical
          robotics to create responsive and intelligent systems. Check out the video to see the robot in action! -->

  <!-- </p>
  <p> -->
  <!-- I used program on<a
            href="https://colab.research.google.com/drive/1hf11j_eM67ogYupwv1YG7da321A2KVGg?usp=sharing"> <span
              style="color: rgb(168, 101, 14);">Google Colab
              Notebook </span></a> to train a model.

          This code allows my robot to "make a decision" based on what it sees. -->
  <!-- To do that I used Deep Learning. I retrained few last layers pertained Mobile Net v2 model. It is called
          Transfer Learning.
        </p>

        <p>
          Using the Raspberry Pi alone, I can only get 2 FPS, but the Coral accelerator allows me to increase that speed
          to
          9 FPS. As you can see, the raspberry pi allows me to create an autonomous robot with near real-time object
          detection, but when the robot is driving and using other sensors, the frame rate drops dramatically. In my
          opinion, the
          Raspberry Pi is a very good tool for basic task, but for a more complex task like ROS, it's probably not good
          enough. I think that something from the Jetson range would
          be a better option because has better GPU.
        </p>

      </div>
    </section>
  </div> -->
  <!-- <div class="wave"></div> -->
  <!-- Videos Tensorflow Raspberry Pi 4 , Google Coral -->
  <!-- <section id="videosUnderDescriptionTensorflow">
    <div class="container">
      <div class="col-lg-12">
        <div class="row">
          <article class="col-sm-offset-0 col-sm-6  col-lg-6 col-md-6">
            <div class="embed-responsive embed-responsive-4by3" id="videoControlerMobileRobot">
              <iframe width="364" height="647"
                src="projects/mobile_robots/fourWheelsRaspberryPi/robot_recognize_go_turn_right_and_stop2.mp4"
                title="TensorflowObjectRecognitionStartStop"
                allow="accelerometer; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                allowfullscreen></iframe>
            </div>
            <p class="description-under-the-photo"><a href="https://github.com/RoboworldMaroA/Roboworld">GO,
                Turn Right and Stop
              </a></p>
            <p>&nbsp;</p>
          </article>

          <article class=" col-sm-6 col-lg-6 col-md-6">
            <div class="embed-responsive embed-responsive-4by3" id="videoControlerMobileRobot3">
              <iframe width="364" height="647"
                src="projects/mobile_robots/fourWheelsRaspberryPi/robot_recognize_go_turn_right_and_stop_raspberry_view2_short.mp4"
                title="Tensorflow Driving Car"
                allow="accelerometer; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                allowfullscreen></iframe>
            </div>
            <p class="description-under-the-photo"><a href="https://github.com/RoboworldMaroA/Roboworld">Object
                Recognition with Google Coral</a></p>
          </article>
        </div>
      </div>
    </div>
  </section> -->


  <!-- Add comments Not Implemented -->

  <!-- <input type="text" id="comment-box" placeholder="Enter comment">
  <button id="post">Post</button>
  <ul id="unordered">

  </ul> -->




  <!--  Footer -->
  <footer class="col-lg-12 col-sm-12 col-md-12">
    <p>
      <!--  email icon -->
      <a href="mailto: marek.augustyn@roboworld.pl"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25"
          fill="currentColor" class="bi bi-envelope" viewBox="0 0 16 16">
          <path
            d="M0 4a2 2 0 0 1 2-2h12a2 2 0 0 1 2 2v8a2 2 0 0 1-2 2H2a2 2 0 0 1-2-2V4Zm2-1a1 1 0 0 0-1 1v.217l7 4.2 7-4.2V4a1 1 0 0 0-1-1H2Zm13 2.383-4.708 2.825L15 11.105V5.383Zm-.034 6.876-5.64-3.471L8 9.583l-1.326-.795-5.64 3.47A1 1 0 0 0 2 13h12a1 1 0 0 0 .966-.741ZM1 11.105l4.708-2.897L1 5.383v5.722Z" />
        </svg>
      </a>

      <!-- linked In icon -->
      <a href="https://www.linkedin.com/in/marekaugustyn/"><svg xmlns="http://www.w3.org/2000/svg" width="24"
          height="24" fill="currentColor" class="bi bi-linkedin" viewBox="0 0 16 16" id="linkedInFooter">
          <path
            d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854V1.146zm4.943 12.248V6.169H2.542v7.225h2.401zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248-.822 0-1.359.54-1.359 1.248 0 .694.521 1.248 1.327 1.248h.016zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016a5.54 5.54 0 0 1 .016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225h2.4z" />
        </svg> </a>

      <!-- GitHub  icon-->
      <a href="https://github.com/RoboworldMaroA/Roboworld"><svg xmlns="http://www.w3.org/2000/svg" width="24"
          height="24" fill="currentColor" class="bi bi-github" viewBox="0 0 16 16">
          <path
            d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z" />
        </svg> </a>
    </p>

    <p>2020-2024 Roboworld - Marek Augustyn</p>
  </footer>

  <!-- JavaScript used to fetch data from API -->
  <script src="javascript/mobileRobots.js?v=1.1"></script>

  <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
    integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
    crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/popper.js@1.12.9/dist/umd/popper.min.js"
    integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q"
    crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/js/bootstrap.min.js"
    integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl"
    crossorigin="anonymous"></script>

</body>

</html>